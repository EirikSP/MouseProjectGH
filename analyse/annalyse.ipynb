{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import sys \n",
    "import scipy as sp\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from facemap_tools.process_tools import *\n",
    "import facemap_tools.plot_utils\n",
    "from facemap_tools.plotting import plot_area\n",
    "import facemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultfolder = \"/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy\" \n",
    "resultfolder = \"/Users/annapaulinehjertvikaasen/Documents/2. UiO/Sommerjobb - Frederik/Sommerjobb 2023/MouseProject/ING71_MEC_230309/AVI/resultsnpy\"\n",
    "\n",
    "procs = create_procs(resultfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Behavioral data\n",
    "\n",
    "def get_experiment_n_day_k(n, k, result_folder = 'resultsnpy'):\n",
    "    #n is a string ex: '04', '10'\n",
    "    #k is on the form yymmdd\n",
    "    base = \"/Volumes/T7/ING71_MEC_\" + str(k)\n",
    "    base = os.path.join(base, 'AVI')\n",
    "    base = os.path.join(base, result_folder)\n",
    "\n",
    "    behavior_base = \"/Volumes/T7/mec-lec-por-data\"\n",
    "    files = os.listdir(base)\n",
    "\n",
    "    experiment_base = 'ING71_MEC_' + str(k) + '_0' + n\n",
    "\n",
    "    exp_filenames = [file for file in files if file[:20] == experiment_base]\n",
    "\n",
    "    complete_proc = []\n",
    "    for file in exp_filenames:\n",
    "        proc = np.load(os.path.join(base, file), allow_pickle=True).item()\n",
    "        complete_proc.extend(proc['pupil'][0]['area'])\n",
    "\n",
    "    negative = np.load(os.path.join(behavior_base, experiment_base + '_negative.npy'), allow_pickle=True)\n",
    "    positive = np.load(os.path.join(behavior_base, experiment_base + '_positive.npy'), allow_pickle=True)\n",
    "    reward = np.load(os.path.join(behavior_base, experiment_base + '_reward.npy'), allow_pickle=True)\n",
    "    aversive = np.load(os.path.join(behavior_base, experiment_base + '_aversive.npy'), allow_pickle=True)\n",
    "\n",
    "    behav = {}\n",
    "    behav['area'] = complete_proc; behav['negative'] = negative; behav['positive'] = positive; behav['reward'] = reward; behav['aversive'] = aversive \n",
    "    \n",
    "    return behav\n",
    "\n",
    "\n",
    "# c_proc, negative ,positive, reward, aversive = get_experiment_n_day_k('03', 230309)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(arr, n=3):\n",
    "    \"\"\"Remove the outliers of an array of pupil area\n",
    "\n",
    "    Args:\n",
    "        arr (array): area\n",
    "        n (int, optional): number of std's which will be included. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    u_lim = np.mean(arr) + n*np.std(arr)\n",
    "    d_lim = np.mean(arr) - n*np.std(arr)\n",
    "    \n",
    "    # arr = np.where((arr<u_lim) & (arr>d_lim), arr, np.mean(arr)) #cannot have nan's when downsampling, don't know whether mean is the best value Could set it to be the std\n",
    "    arr = np.where(arr < u_lim, arr, u_lim)\n",
    "    arr = np.where(arr > d_lim, arr, d_lim)\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking into pupil area plotted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in list(procs.keys())[::5]:\n",
    "    proc = procs[filename]\n",
    "    plot_area(proc)\n",
    "    plot_area(proc, zoom=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = list(procs.values())[-1]\n",
    "\n",
    "plt.plot(proc['pupil'][0]['area'])\n",
    "plt.plot(proc['pupil'][0]['area_smooth'])\n",
    "plt.xlim((500,800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(procs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(procs['ING71_MEC_230309_001_Behav_Fr1-11947_proc']['pupil'][0]['area'])\n",
    "plt.plot(procs['ING71_MEC_230309_001_Behav_Fr1-11947_proc']['pupil'][0]['area_smooth'])\n",
    "# plt.xlim((500,800))\n",
    "# plt.ylim((100,125))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More interesting data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = list(procs.values())[0]\n",
    "\n",
    "print(proc.keys())\n",
    "print(proc['pupil'][0].keys())\n",
    "\n",
    "print(np.shape(proc['pupil'][0]['axdir']))\n",
    "print(np.shape(proc['pupil'][0]['axlen']))\n",
    "# print(proc['pupil'][0]['axdir'])\n",
    "# print(proc['pupil'][0]['axlen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(proc['pupil'][0]['axlen'][:,0])\n",
    "plt.plot(proc['pupil'][0]['axlen'][:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like axlen and axdir refer to the axis that make up the tracker ellipse around the pupil. They seem to coincide very well with the area, which is expected as the area is calculated from the ellipse. We assume that axdir is the direction of the two axis making up the ellipse, and axlen the length of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc['rois'][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like rois contain little data of interest for further analysis. It could be interesting for understanding what we have done when creating the ROIs, so one could argue that the proc-files (per folder, as the ROI is the same for an entire folder. Could call it sample or something) should be saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Ly', 'Lx' \n",
    "print(proc['Lx'])\n",
    "print(proc['Ly'])\n",
    "print(86/3*66/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume the pupil makes up about 1/3 of the x-dir and y-dir. We see that the number of pixels within this fram seem to correspond with the y-axis of the area plots. \n",
    "\n",
    "When trying with two different files (within the same folder). Lx and Ly stay constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'avgframe':  list of average frames for each video from a subset of frames (binned by sbin) \n",
    "# 'avgmotion':  list of average motions for each video from a subset of frames (binned by sbin)\n",
    "print(np.shape(proc['avgframe']))\n",
    "print(proc['avgframe'])\n",
    "plt.plot(proc['avgframe'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(proc['avgmotion']))\n",
    "print(proc['avgmotion'])\n",
    "plt.plot(proc['avgmotion'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_proc, negative ,positive, reward, aversive = get_experiment_n_day_k('03', 230309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = len(positive)\n",
    "ds_proc = sp.signal.resample(c_proc, n_points) #ds stands for downsampled\n",
    "\n",
    "plt.plot(ds_proc)\n",
    "plt.plot(c_proc)\n",
    "plt.show()\n",
    "\n",
    "#Plot with downsampeled \n",
    "plt.plot(ds_proc)\n",
    "plt.scatter(np.arange(len(positive)), positive*ds_proc, 5, color='r')\n",
    "# plt.xlim(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using decimate\n",
    "\n",
    "ds_proc_d  = sp.signal.decimate(c_proc, 2)\n",
    " \n",
    "plt.plot(ds_proc_d)\n",
    "plt.plot(c_proc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking various ROIs for processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to check the difference of creating one sampl.npy-file per folder (general) and compare with the results from creating one per video (individual). Starting with folder /Volumes/T7/ING71_MEC_230309/AVI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading general:\n",
    "resultfolder_general = '/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy' \n",
    "procs_general = create_procs(resultfolder_general)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading individuals and comparing:\n",
    "\n",
    "proc_001_ind = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_001_Behav_Fr1-11947_proc.npy', allow_pickle=True).item()\n",
    "proc_001_gen = procs_general['ING71_MEC_230309_001_Behav_Fr1-11947_proc']\n",
    "\n",
    "plot_area(proc_001_gen, show=False)\n",
    "plot_area(proc_001_ind)\n",
    "\n",
    "\n",
    "proc_002_ind = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_002_Behav_Fr11949-23896_proc.npy', allow_pickle=True).item()\n",
    "proc_002_gen = procs_general['ING71_MEC_230309_002_Behav_Fr11949-23896_proc']\n",
    "\n",
    "plot_area(proc_002_gen, show=False)\n",
    "plot_area(proc_002_ind)\n",
    "\n",
    "\n",
    "proc_003_ind = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_003_Behav_Fr23897-35844_proc.npy', allow_pickle=True).item()\n",
    "proc_003_gen = procs_general['ING71_MEC_230309_003_Behav_Fr23897-35844_proc']\n",
    "\n",
    "plot_area(proc_003_gen, show=False)\n",
    "plot_area(proc_003_ind)\n",
    "\n",
    "\n",
    "proc_009_ind = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_009_Behav_Fr47793-59740_proc.npy', allow_pickle=True).item()\n",
    "proc_009_gen = procs_general['ING71_MEC_230309_009_Behav_Fr47793-59740_proc']\n",
    "\n",
    "plot_area(proc_009_gen, show=False)\n",
    "plot_area(proc_009_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the shape is kept rather constant although the absolute value seems to vary some. One can assume that some of this is due to the individual altering of saturation being better than the general one. Seems like the pupil is mostly within the defined region.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checkin the original one (should overlap completely):\n",
    "proc_000_ind = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_000_Behav_Fr1-9973_proc_wrong.npy', allow_pickle=True).item()\n",
    "proc_000_gen = procs_general['ING71_MEC_230309_000_Behav_Fr1-9973_proc']\n",
    "\n",
    "plot_area(proc_000_gen, show=False)\n",
    "plot_area(proc_000_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting! Not even the original one overlaps completely... Here the .npy-file was first processed in the GUI (yielding the green graph) and then that proc-file was used to process the entire folder (including the purple graph). Could it be that there is some randomness to the calculations which yield the difference in result? This was very interesting, indeed. Could it be that the saturation is not saved in the proc-file which is used for processing, but only employed when processing inside the GUI? This could be checked out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_000_gen['rois'][0]['saturation'])\n",
    "print(proc_000_ind['rois'][0]['saturation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very interesting... It seems the saturation is different in the two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_000_gen['rois'][0]['yrange'])\n",
    "print(proc_000_ind['rois'][0]['yrange'])\n",
    "\n",
    "print(proc_000_gen['rois'][0]['xrange'])\n",
    "print(proc_000_ind['rois'][0]['xrange'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_000_gen['rois'][0]['ellipse'])\n",
    "print(proc_000_ind['rois'][0]['ellipse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(proc_000_ind['rois'][0]['ellipse'], cmap='plasma')\n",
    "plt.imshow(proc_000_gen['rois'][0]['ellipse'], alpha=0.7, cmap='plasma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that there is not a complete overlap between the two. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare procs for '/Volumes/T7/ING71_MEC_230317'\n",
    "Would like to compare proc before and after processing (through facemap_tools)\n",
    "\n",
    "Now with folder '/Volumes/T7/ING71_MEC_230317' (would have liked to try with the other mouse, but this is the only data I have access to at the moment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_b4_proc = np.load('/Volumes/T7/ING71_MEC_230317/AVI/ING71_MEC_230317_000_Behav_Fr1-9973_unproc_proc.npy', allow_pickle=True).item()\n",
    "proc_af_proc = np.load('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy/ING71_MEC_230317_000_Behav_Fr1-9973_proc.npy', allow_pickle=True).item()\n",
    "\n",
    "print(proc_b4_proc['rois'])\n",
    "print(proc_af_proc['rois'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seem to be identical! \n",
    "\n",
    "Would now like to process it trough the gui and compare it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_af_gui_proc = np.load('/Volumes/T7/ING71_MEC_230317/AVI/ING71_MEC_230317_000_Behav_Fr1-9973_proc.npy', allow_pickle=True).item()\n",
    "\n",
    "print(proc_b4_proc['rois'])\n",
    "print(proc_af_gui_proc['rois'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What? This still seem identical..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_area(proc_af_proc, show=False)\n",
    "plot_area(proc_af_gui_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, so now it completely overlaps... What did I do before? Haha.\n",
    "\n",
    "Perhaps I sent in the  wrong npy-file while processing the folder? Perhaps I sent in the wrong path and it ended up using sample or something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at sample.npy to see if this is the one who's been used \n",
    "proc_sample = np.load('/Users/annapaulinehjertvikaasen/Documents/2. UiO/Sommerjobb - Frederik/Sommerjobb 2023/MouseProject/MouseProjectGH/ING71_MEC_230309/AVI/sample.npy', allow_pickle=True).item()\n",
    "print(proc_sample['rois'][0]['saturation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_sample_2 = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_sample.npy', allow_pickle=True).item()\n",
    "print(proc_sample_2['rois'][0]['saturation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! Here we see what's happened! I have perhaps forgotten to send in the a path to the proc-file. \n",
    "\n",
    "However, when looking at the terminal history, this is not what happened. Looks like it should have used the path I sent in, also when looking at the function. \n",
    "\n",
    "![](figures/terminal.png)\n",
    "\n",
    "To test this hypothesis though, we could process the ---_sample.npy file and compare. Should then see a complete overlap. If this is the case then the results above are valid. \n",
    "\n",
    "\n",
    "However, I cannot upload ---_sample.npy to the GUI since Eirik created that, hahah.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next folder: '/Volumes/T7/ING71_MEC_230317'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs_17_general = create_procs('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_17_001_ind = np.load('/Volumes/T7/ING71_MEC_230317/AVI/ING71_MEC_230317_001_Behav_Fr1-11947_proc.npy', allow_pickle=True).item()\n",
    "proc_17_001_gen = procs_17_general['ING71_MEC_230317_001_Behav_Fr1-11947_proc']\n",
    "\n",
    "plot_area(proc_17_001_gen, show=False)\n",
    "plot_area(proc_17_001_ind)\n",
    "\n",
    "\n",
    "proc_17_002_ind = np.load('/Volumes/T7/ING71_MEC_230317/AVI/ING71_MEC_230317_002_Behav_Fr11949-23896_proc.npy', allow_pickle=True).item()\n",
    "proc_17_002_gen = procs_17_general['ING71_MEC_230317_002_Behav_Fr11949-23896_proc']\n",
    "\n",
    "plot_area(proc_17_002_gen, show=False)\n",
    "plot_area(proc_17_002_ind)\n",
    "\n",
    "\n",
    "proc_17_003_ind = np.load('/Volumes/T7/ING71_MEC_230317/AVI/ING71_MEC_230317_003_Behav_Fr23897-35844_proc.npy', allow_pickle=True).item()\n",
    "proc_17_003_gen = procs_17_general['ING71_MEC_230317_003_Behav_Fr23897-35844_proc']\n",
    "\n",
    "plot_area(proc_17_003_gen, show=False)\n",
    "plot_area(proc_17_003_ind, alpha=0.65)\n",
    "\n",
    "\n",
    "proc_17_009_ind = np.load('/Volumes/T7/ING71_MEC_230317/AVI/ING71_MEC_230317_009_Behav_Fr47793-59738_proc.npy', allow_pickle=True).item()\n",
    "proc_17_009_gen = procs_17_general['ING71_MEC_230317_009_Behav_Fr47793-59738_proc']\n",
    "\n",
    "plot_area(proc_17_009_gen, show=False)\n",
    "plot_area(proc_17_009_ind, alpha=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again it looks like the general shape of the area stays constant. In most cases there seems to be a shift, perhaps due to the saturation settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare area and area smooth (Runwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas, areas_smooth = create_areas('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(areas['000'])\n",
    "plt.plot(areas_smooth['000'], alpha=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like 'area smooth' differs from 'area' quite alot, even though the general shape of the signal is the same. However, I find it very strange that 'amooth' has some \"blinking\" that area does not have..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(areas['001'])\n",
    "plt.plot(areas_smooth['001'], alpha=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the 'area smooth' overlaps rather well with the 'area' in this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(areas['002'])\n",
    "plt.plot(areas_smooth['002'], alpha=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(areas['003'])\n",
    "plt.plot(areas_smooth['003'], alpha=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(areas['009'])\n",
    "plt.plot(areas_smooth['009'], alpha=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in 000 and 009 the 'area smooth' seems to create downwards spikes. Now, zooming in (the 4th 009 video, ING71_MEC_230317_009_Behav_Fr35845-47792):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(areas['009'])\n",
    "plt.plot(areas_smooth['009'], alpha=0.65)\n",
    "plt.xlim((36000,48000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the GUI, these spikes seem to be gone. Also, when inspecting the video where the spikes should be, I found nothing of interest. However, the mouse blinked around 5500 (In pur plot that shoud be 41 500), and this was not marked with a spike. It also blinked around 6800 (42 800). Both of these blinks were marked by the SVD. It should also be mentioned that the pupil in this case was a little bit cut off at the bottom.\n",
    "\n",
    "It seems more and more like the software lacks in the classifications of blinking (at least when looking at the area). However, this is not our field of interest and might be ignored. \n",
    "\n",
    "In the comparison of area and area smooth we have yet to see an advantage of either as opposed to the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavioral data\n",
    "\n",
    "Here we use the downsampling currently yielding the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Could take a dictionary (from get_behav_data) as an argument instead. Would solve the label-problem \n",
    "\n",
    "\n",
    "def ds_and_plot(behav_dict, cue_keys=['positive', 'negative'], behav_keys=['reward', 'aversive'], xlim=(0,12000)):\n",
    "    \"\"\"Downsample and plot\n",
    "\n",
    "    Args:\n",
    "        area (array): run_based area array\n",
    "        cues (list): list of arrays of cues\n",
    "        behavs (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if not isinstance(cue_keys, (list, np.ndarray)):\n",
    "        cue_keys = [cue_keys]\n",
    "    if not isinstance(behav_keys, (list, np.ndarray)):\n",
    "        behav_keys = [behav_keys]\n",
    "\n",
    "    # Remove outliers:\n",
    "    area = behav_dict['area']\n",
    "    area = remove_outliers(area)\n",
    "\n",
    "    # Downsize\n",
    "    n_points = len(behav_dict[[cue_keys][0][0]])\n",
    "    ds_area = sp.signal.resample(area, n_points)\n",
    "\n",
    "    # Plot area\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(ds_area)\n",
    "\n",
    "    # Plot cues and behaviors \n",
    "    x = np.arange(n_points)\n",
    "    max = np.max(ds_area)\n",
    "\n",
    "    for cue in cue_keys:\n",
    "        plt.fill_between(x, 0, max, where = (behav_dict[cue]==1), alpha=0.5, label=cue)\n",
    "\n",
    "    for behav_key in behav_keys: \n",
    "        behav = behav_dict[behav_key]\n",
    "        x_filtered = x[(behav > 0.0)]\n",
    "        behav_filtered = behav[(behav > 0.0)]\n",
    "        plt.scatter(x_filtered, behav_filtered*np.max(ds_area), 20, label = behav_key)\n",
    "\n",
    "    plt.xlim(xlim)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine oscillations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_17_1 = get_experiment_n_day_k('01', 230317)\n",
    "ds_and_plot(behav_17_1, xlim=(0,4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_17_2 = get_experiment_n_day_k('02', 230317)\n",
    "ds_and_plot(behav_17_2, xlim=(0,24000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the pupil size drops almost every time at the end of a cue (not necessarily for a long time). Often it spikes up right afterwards. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting cue-sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = remove_outliers(behav_17_1['area'])\n",
    "pos = behav_17_1['positive']\n",
    "neg = behav_17_1['negative']\n",
    "area = sp.signal.resample(area, len(pos))\n",
    "\n",
    "anti_pos_idx = np.argwhere(pos==0)\n",
    "pos_area = area.copy()\n",
    "pos_area[anti_pos_idx] = np.nan\n",
    "plt.plot(area)\n",
    "plt.plot(pos_area)\n",
    "\n",
    "anti_neg_idx = np.argwhere(neg==0)\n",
    "neg_area = area.copy()\n",
    "neg_area[anti_neg_idx] = np.nan\n",
    "plt.plot(neg_area)\n",
    "\n",
    "plt.xlim((0,4000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a little help from a friend\n",
    "\n",
    "def cue_sections(cue, after_cue=300, plot=True):\n",
    "    \"\"\"Extract sections from area where cue is present + some frames after cue (after_cue). the mean and std should be taken per frame\n",
    "    \"\"\"\n",
    "\n",
    "    indices_ones = np.where(cue == 1)[0]\n",
    "    sections_starts = np.where(np.diff(indices_ones) > 1)[0] + 1\n",
    "    sections_ends = np.where(np.diff(indices_ones) > 1)[0] + 2\n",
    "    sections_starts = np.insert(sections_starts, 0, 0)\n",
    "    sections_ends = np.append(sections_ends, len(indices_ones))\n",
    "\n",
    "    sections = []\n",
    "\n",
    "    length = 95 + after_cue\n",
    "\n",
    "    for start, end in zip(sections_starts, sections_ends):\n",
    "        section = area[indices_ones[start]:indices_ones[end-1] + after_cue]     #the end-1 could perhaps be avoided by changing the code above.\n",
    "\n",
    "        # Need to make sure they're the same length to be able to do np.mean/std. \n",
    "        if len(section) < length:\n",
    "            # Padding with NaNs at the end to match the maximum length\n",
    "            section = np.pad(section, (0, length - len(section)), mode='constant', constant_values=np.nan)\n",
    "        elif len(section) > length:\n",
    "            # Truncating from the end to match the maximum length\n",
    "            section = section[:length]\n",
    "\n",
    "        sections.append(section)\n",
    "        # print(f\"Section {start//2 + 1}: {section}\")\n",
    "\n",
    "\n",
    "    mean_area = np.mean(sections,0)\n",
    "    area_std = np.std(sections, 0)\n",
    "    x = np.arange(length)\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(x, np.mean(sections,0))\n",
    "        plt.fill_between(x, mean_area+area_std, mean_area-area_std, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "cue_sections(pos)\n",
    "cue_sections(neg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_17_2 = get_experiment_n_day_k('02', 230317)\n",
    "ds_and_plot(behav_17_2, xlim=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wtf, either something has gone wrong in the recording or this mouse had an almost perfect run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_17_3 = get_experiment_n_day_k('03', 230317)\n",
    "ds_and_plot(behav_17_3, xlim=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey, it seriously looks like the mouse has learnt the system (from '002' and '003' 230317). According to some of the articles on cognitive load theory, I assume this would mean the pupil should be smaller than the other days (see https://journals.sagepub.com/doi/abs/10.1177/1071181311551049, or logg in Word). Let's compare with some previous days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_09_1 = get_experiment_n_day_k('01', 230309)\n",
    "ds_and_plot(behav_09_1, xlim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_10_1 = get_experiment_n_day_k('01', 230310)\n",
    "ds_and_plot(behav_10_1, xlim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_14_1 = get_experiment_n_day_k('01', 230314, result_folder='resultsnpy_E_mac')\n",
    "ds_and_plot(behav_14_1, xlim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(behav_09_1['area'])\n",
    "# plt.plot(behav_14_1['area'])\n",
    "plt.plot(behav_17_2['area'], alpha=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it looks like the run where the mouse scores high has a larger pupil area. However, the comparison between sessions could be difficult as there are some uncertainties when processing the data folder wise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwrite Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overwrite_filenames(result_folder, avi_folder=None):\n",
    "    \"\"\"\n",
    "    Takes in a resultfolder (full of npy-files) and overwrites the 'filenames' and 'save_path' so that the procs contain the correct file-path and can be evaluated in the gui. \n",
    "\n",
    "    eg. results_folder: '/Volumes/T7/ING71_MEC_230310/AVI/resultsnpy' \n",
    "    results_folder is the same as save_path\n",
    "\n",
    "    filenames requires the avi file corresponding to the npy-file.\n",
    "    \"\"\"\n",
    "\n",
    "    #set avi_folder to the folder \"above\" result_folder:\n",
    "    # Simply removing the /resultsnpy (seems too specific, but) \n",
    "    # if avi_folder == None:\n",
    "    #     avi_folder = result_folder[:-11]\n",
    "    if avi_folder == None:\n",
    "        avi_folder = result_folder[:32]\n",
    "    ### NB! Now it only works with mac! \n",
    "\n",
    "\n",
    "    files = os.listdir(result_folder)\n",
    "    clean_files = []\n",
    "\n",
    "    #Checks for .avi files and catches exception if filenames are shorter than 4 letters.\n",
    "    for file in files:\n",
    "        try:\n",
    "            if file[-4:] == \".npy\":\n",
    "                clean_files.append(file)\n",
    "        except:\n",
    "            print('Invalid file name')\n",
    "\n",
    "    for filename in clean_files:\n",
    "        npy_path = os.path.join(result_folder, filename)\n",
    "        proc = np.load(npy_path, allow_pickle=True).item() \n",
    "\n",
    "        avi_filename = filename[:-9] + '.avi'\n",
    "        avi_path = os.path.join(avi_folder, avi_filename)\n",
    "\n",
    "        #Overwrite:\n",
    "        proc['filenames'] = [[avi_path]]\n",
    "        proc['save_path'] = result_folder\n",
    "\n",
    "        np.save(npy_path, proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite_filenames('/Volumes/T7/ING71_MEC_230310/AVI/resultsnpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the two procs \n",
    "\n",
    "proc_09 = np.load('/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy/ING71_MEC_230309_000_Behav_Fr1-9973_proc.npy', allow_pickle=True).item()\n",
    "proc_10 = np.load('/Volumes/T7/ING71_MEC_230310/AVI/resultsnpy/ING71_MEC_230310_000_Behav_Fr1-9973_proc.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_09['filenames'])\n",
    "print(proc_10['filenames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_09['save_path'])\n",
    "print(proc_10['save_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite_filenames('/Volumes/T7/ING71_MEC_230313/AVI/resultsnpy_E_mac')\n",
    "# overwrite_filenames('/Volumes/T7/ING71_MEC_230314/AVI/resultsnpy_E_mac')\n",
    "# overwrite_filenames('/Volumes/T7/ING71_MEC_230315/AVI/resultsnpy_E_mac')\n",
    "# overwrite_filenames('/Volumes/T7/ING71_MEC_230316/AVI/resultsnpy_E_mac')\n",
    "overwrite_filenames('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy_E_mac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For sample file\n",
    "It would be cool to be able to test the sample-file on several avi-files before processing. However, that would mean preprocessing it before every load :/ Minght not be smooth enough, and we could maybe just process it and then check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_sample = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_sample.npy', allow_pickle=True).item()\n",
    "print(proc_sample['filenames'], proc_sample['save_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Bonanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def plot_areas(run_based_folder):\n",
    "    areas, areas_smooth = create_areas(run_based_folder)\n",
    "    nrows = len(areas.keys())\n",
    "\n",
    "    areas_sorted = OrderedDict(sorted(areas.items()))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,20), nrows=nrows, ncols=1)\n",
    "    for i in range(nrows):\n",
    "        key = list(areas_sorted.keys())[i]\n",
    "        # ax[i].plot(areas[key])\n",
    "        ax[i].plot(areas_smooth[key], alpha=0.65)\n",
    "        ax[i].set_title(run_based_folder + '  Run: ' + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areas('/Volumes/T7/ING71_MEC_230310/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areas('/Volumes/T7/ING71_MEC_230314/AVI/resultsnpy_E/run_based')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areas('/Volumes/T7/ING71_MEC_230315/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areas('/Volumes/T7/ING71_MEC_230316/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areas('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areas('/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy/run_based')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes for a more general plotting:\n",
    "take the keys into direct consideration as they seem to vary quite a lot (done)\n",
    "\n",
    "\n",
    "What's annoying about these results is that I can go into the gui and look into them... I mean some of them seem weird. (This is fixed now! Just use the 'overwrite_filenam'-function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting runs on top of eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_runs(run_based_folder):\n",
    "    areas, areas_smooth = create_areas(run_based_folder)\n",
    "    nkeys = len(areas.keys())\n",
    "\n",
    "    areas_sorted = OrderedDict(sorted(areas.items()))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    for i in range(nkeys):\n",
    "        key = list(areas_sorted.keys())[i]\n",
    "        # ax.plot(areas[key], label=key)\n",
    "        ax.plot(areas_smooth[key], label=key)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230310/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230313/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230314/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230315/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230316/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now with scaling \n",
    "\n",
    "Want to compare eg training runs (001/002/003) with baseline run (000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "def plot_runs(run_based_folder, keys_idx=None, rmv_out=False):\n",
    "    areas, areas_smooth = create_areas(run_based_folder)\n",
    "\n",
    "    nkeys = len(areas.keys())\n",
    "    if keys_idx==None:\n",
    "        keys_idx = list(range(nkeys))\n",
    "\n",
    "    areas_sorted = OrderedDict(sorted(areas.items()))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    for i in keys_idx:\n",
    "        key = list(areas_sorted.keys())[i]\n",
    "\n",
    "        area_smooth = areas_smooth[key]\n",
    "        if rmv_out:\n",
    "            area_smooth = remove_outliers(area_smooth)\n",
    "        # ax.plot(areas[key], label=key)\n",
    "        ax.plot(minmax_scale(area_smooth), label=key)\n",
    "    ax.set_xlim((0,1000))\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_runs('/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy_E/run_based', [0,1], rmv_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_runs('/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy_E/run_based', [0, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would say 009 and 000 look quite similar in this case. Seems like the training runs have a more caotic pattern with less large oscillations. The resting run has some very large oscillations. However, I feel like the large oscillations in the BL and resting run might be easier to see as they have some large deviations squishing the rest of the graph together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing with a new ROI\n",
    "\n",
    "In this section we will compare the results run on Eirik's computer (possibly run with one ROI for all folders) and Anna's (one ROI per folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(avi_folder):\n",
    "    \"\"\"\n",
    "    Assuming the avi_folder contains two result folders. \n",
    "    \"\"\"\n",
    "    RB_path = os.path.join(avi_folder, 'resultsnpy/run_based')          #Path to runbased folder\n",
    "    RB_path_E = os.path.join(avi_folder, 'resultsnpy_E/run_based')\n",
    "\n",
    "    areas = create_areas(RB_path)[0]\n",
    "    areas_E = create_areas(RB_path_E)[0]\n",
    "\n",
    "    nrows = len(areas.keys())\n",
    "\n",
    "    areas_sorted = OrderedDict(sorted(areas.items()))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,20), nrows=nrows, ncols=1)\n",
    "    for i in range(nrows):\n",
    "        key = list(areas_sorted.keys())[i]\n",
    "        ax[i].plot(areas[key])\n",
    "        ax[i].plot(areas_E[key], alpha=0.65)\n",
    "        ax[i].set_title(avi_folder + '  Run: ' + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_results('/Volumes/T7/ING71_MEC_230310/AVI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have looked into the case of 010 (last plot); seems to be related to a lot of blinking in combination with something that looks like grooming. \n",
    "\n",
    "The increase in 001 could perhaps be the adjustment to a brighter light."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_results('/Volumes/T7/ING71_MEC_230309/AVI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Someting interesting! It looks like the values go below 0. And, NB, this is befor downsampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_results('/Volumes/T7/ING71_MEC_230317/AVI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT\n",
    "\n",
    "In this section we would like to explore FFT on the pupil-areas to see whether there appears some \"system\" in the frequency. Perhaps we can see some of the same frequencies in the training runs and the relaxing runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas, areas_smooth = create_areas('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy/run_based')\n",
    "\n",
    "area_0 = areas['000']\n",
    "area_0  =remove_outliers(area_0)\n",
    "area_0_fft = np.fft.fft(area_0)\n",
    "\n",
    "x = np.arange(len(area_0))\n",
    "freq = np.fft.fftfreq(x.shape[-1])  # https://numpy.org/doc/stable/reference/generated/numpy.fft.fft.html\n",
    "\n",
    "plt.plot(freq, area_0_fft.real)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(freq, area_0_fft.imag)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(freq, area_0_fft.real)\n",
    "plt.ylim((-50000, 50000))\n",
    "plt.plot(freq, area_0_fft.imag, alpha=0.65)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I interpret this correctly (real component refering to the amplitude of the certain frequency and the imaginary the position/alignment of each frequency(not as interesting)), it seems like most of the relevant components have frequencies around 0 (could there be some calculation limitations here?). However, there is a clear frequency around 0.18 (negative) and 0.41. \n",
    "\n",
    "Info about the x-axis:\n",
    "\"By default, np.fft.fftfreq() generates an array of frequency values in the range [-0.5, 0.5), where 0 Hz corresponds to the center of the frequency range. The frequencies are in units of cycles per sample... 'cycle' refers to a full oscillation of a sinusoidal wave, i.e., one complete period of the wave... The frequency of a wave is the number of cycles it completes in one second. However, in the FFT output, the frequencies are given in a normalized form with respect to the sample rate. (sample rate can be eg. 1000 samples per second (1kHz))\" \n",
    "\n",
    "\" freq=0 correspond to the sample rate\" So in our case one cycle per frame (?)\n",
    "\n",
    "\"the frequency values obtained from the FFT output cannot directly represent frequencies higher than the Nyquist frequency, which is half of the sampling frequency.\"\n",
    "\n",
    " (see chatGPT under \"complex fourier comp...\" for more info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DC Component: The freq=0 in the FFT output represents the DC (direct current) component or the average value of the signal. In many real-world signals, there is often a DC offset, which means the signal has a non-zero mean value. This constant component appears at freq=0 in the FFT result, and its magnitude can be much larger than other frequency components, especially if the signal is not centered around zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_2 = areas_smooth['002']\n",
    "area_2 = remove_outliers(area_2)\n",
    "area_2 = minmax_scale(area_2) - 0.5 #This is a weird scaling:) Want it to be centered around 0\n",
    "area_2_fft = np.fft.fft(area_2)\n",
    "\n",
    "x = np.arange(len(area_2))\n",
    "freq = np.fft.fftfreq(x.shape[-1])  # https://numpy.org/doc/stable/reference/generated/numpy.fft.fft.html\n",
    "\n",
    "plt.plot(freq, area_2_fft.real)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(freq, area_2_fft.imag)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(freq, area_2_fft.real)\n",
    "plt.ylim((-500, 500))\n",
    "plt.plot(freq, area_2_fft.imag, alpha=0.65)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like centering the signal around 0 before the FFT reduces the large values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with some different runs on top of eachother:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runs_FFT(run_based_folder, keys=None, areas_smooth=False, rmv_out=True, scale=True, ylim=(-1000, 1000)):\n",
    "    areas, areas_smooth = create_areas(run_based_folder)\n",
    "\n",
    "    if areas_smooth:\n",
    "        areas = areas_smooth\n",
    "\n",
    "    areas_sorted = OrderedDict(sorted(areas.items()))\n",
    "    \n",
    "    if keys==None:\n",
    "        keys = list(areas_sorted.keys())\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    \n",
    "    for i, key in enumerate(keys):\n",
    "        area = areas[key]\n",
    "\n",
    "        if rmv_out:\n",
    "            area = remove_outliers(area)\n",
    "\n",
    "        if scale:\n",
    "            area = minmax_scale(area) - 0.5\n",
    "\n",
    "        ### FFT:\n",
    "        area_fft = np.fft.fft(area)\n",
    "        x = np.arange(len(area))\n",
    "        freq = np.fft.fftfreq(x.shape[-1])\n",
    "        \n",
    "        ### Plot:\n",
    "        ax.plot(freq, area_fft.real, label=key, alpha=1 - 0.1*i)\n",
    "    ax.set_ylim(ylim)\n",
    "    # ax.set_xlim((-0.1,0.1))\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_runs_FFT('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy/run_based')\n",
    "plot_runs_FFT('/Volumes/T7/ING71_MEC_230316/AVI/resultsnpy_E_mac/run_based')\n",
    "plot_runs_FFT('/Volumes/T7/ING71_MEC_230315/AVI/resultsnpy_E_mac/run_based')\n",
    "plot_runs_FFT('/Volumes/T7/ING71_MEC_230314/AVI/resultsnpy_E_mac/run_based')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that '000' and '009' both have high amplitudes of 0.41. 001,002,003 all have some amplitude around 0.07 (which it seems like 000 and 009 as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT(area, rmv_out=True, scale=True):\n",
    "    if rmv_out: area = remove_outliers(area)\n",
    "    if scale: area = minmax_scale(area) - 0.5\n",
    "\n",
    "    ### FFT:\n",
    "    area_fft = np.fft.fft(area)\n",
    "    x = np.arange(len(area))\n",
    "    freq = np.fft.fftfreq(x.shape[-1])\n",
    "\n",
    "    return freq, area_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want plot the frequencies with high amplitude over the areas \n",
    "areas, areas_smooth = create_areas('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy/run_based')\n",
    "area_3 = areas['003']\n",
    "freq, area_3_fft = FFT(area_3)\n",
    "\n",
    "\n",
    "amp_idx = np.argwhere(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 1    # 1 measure per frame \n",
    "# freq=0.1 takes 10 samples for it to complete one cycle\n",
    "idx = np.argwhere((freq>0.075) & (freq<0.08) & (area_3_fft.real > 100))\n",
    "print(freq[idx], area_3_fft[idx])\n",
    "\n",
    "selected_freq = np.zeros_like(area_3_fft)\n",
    "selected_freq[idx] = area_3_fft[idx]\n",
    "selected_signal = np.fft.ifft(selected_freq)\n",
    "\n",
    "plt.plot(selected_signal.real)\n",
    "# plt.xlim((0,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
