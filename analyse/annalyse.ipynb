{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import sys \n",
    "import scipy as sp\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from facemap_tools.process_tools import *\n",
    "import facemap_tools.plot_utils\n",
    "from facemap_tools.plotting import plot_area\n",
    "import facemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultfolder = \"/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy\" \n",
    "resultfolder = \"/Users/annapaulinehjertvikaasen/Documents/2. UiO/Sommerjobb - Frederik/Sommerjobb 2023/MouseProject/ING71_MEC_230309/AVI/resultsnpy\"\n",
    "\n",
    "procs = create_procs(resultfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Behavioral data\n",
    "\n",
    "def get_experiment_n_day_k(n, k):\n",
    "    #n is a string ex: '04', '10'\n",
    "    #k is on the form yymmdd\n",
    "    base = \"/Volumes/T7/ING71_MEC_\" + str(k)\n",
    "    base = os.path.join(base, 'AVI')\n",
    "    base = os.path.join(base, 'resultsnpy')\n",
    "\n",
    "    behavior_base = \"/Volumes/T7/mec-lec-por-data\"\n",
    "    files = os.listdir(base)\n",
    "\n",
    "    experiment_base = 'ING71_MEC_' + str(k) + '_0' + n\n",
    "\n",
    "    exp_filenames = [file for file in files if file[:20] == experiment_base]\n",
    "\n",
    "    complete_proc = []\n",
    "    for file in exp_filenames:\n",
    "        proc = np.load(os.path.join(base, file), allow_pickle=True).item()\n",
    "        complete_proc.extend(proc['pupil'][0]['area'])\n",
    "\n",
    "    negative = np.load(os.path.join(behavior_base, experiment_base + '_negative.npy'), allow_pickle=True)\n",
    "    positive = np.load(os.path.join(behavior_base, experiment_base + '_positive.npy'), allow_pickle=True)\n",
    "    reward = np.load(os.path.join(behavior_base, experiment_base + '_reward.npy'), allow_pickle=True)\n",
    "    aversive = np.load(os.path.join(behavior_base, experiment_base + '_aversive.npy'), allow_pickle=True)\n",
    "    \n",
    "    return complete_proc, negative, positive, reward, aversive\n",
    "\n",
    "\n",
    "# c_proc, negative ,positive, reward, aversive = get_experiment_n_day_k('03', 230309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_behav_data(n, k):\n",
    "    #n is a string ex: '04', '10'\n",
    "    #k is on the form yymmdd\n",
    "\n",
    "    base = \"/Volumes/T7/ING71_MEC_\" + str(k)\n",
    "    base = os.path.join(base, 'AVI')\n",
    "    base = os.path.join(base, 'resultsnpy')\n",
    "\n",
    "    behavior_base = \"/Volumes/T7/mec-lec-por-data\"\n",
    "    files = os.listdir(base)\n",
    "\n",
    "    experiment_base = 'ING71_MEC_' + str(k) + '_0' + n\n",
    "\n",
    "    negative = np.load(os.path.join(behavior_base, experiment_base + '_negative.npy'), allow_pickle=True)\n",
    "    positive = np.load(os.path.join(behavior_base, experiment_base + '_positive.npy'), allow_pickle=True)\n",
    "    reward = np.load(os.path.join(behavior_base, experiment_base + '_reward.npy'), allow_pickle=True)\n",
    "    aversive = np.load(os.path.join(behavior_base, experiment_base + '_aversive.npy'), allow_pickle=True)\n",
    "\n",
    "    behav = {}\n",
    "    behav['negative'] = negative; behav['positive'] = positive; behav['reward'] = reward; behav['aversive'] = aversive \n",
    "\n",
    "    return behav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(arr, n=3):\n",
    "    \"\"\"Remove the outliers of an array of pupil area\n",
    "\n",
    "    Args:\n",
    "        arr (array): area\n",
    "        n (int, optional): number of std's which will be included. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    u_lim = np.mean(arr) + n*np.std(arr)\n",
    "    d_lim = np.mean(arr) - n*np.std(arr)\n",
    "    \n",
    "    # arr = np.where((arr<u_lim) & (arr>d_lim), arr, np.mean(arr)) #cannot have nan's when downsampling, don't know whether mean is the best value Could set it to be the std\n",
    "    arr = np.where(arr < u_lim, arr, u_lim)\n",
    "    arr = np.where(arr > d_lim, arr, d_lim)\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking into pupil area plotted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in list(procs.keys())[::5]:\n",
    "    proc = procs[filename]\n",
    "    plot_area(proc)\n",
    "    plot_area(proc, zoom=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = list(procs.values())[-1]\n",
    "\n",
    "plt.plot(proc['pupil'][0]['area'])\n",
    "plt.plot(proc['pupil'][0]['area_smooth'])\n",
    "plt.xlim((500,800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(procs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(procs['ING71_MEC_230309_001_Behav_Fr1-11947_proc']['pupil'][0]['area'])\n",
    "plt.plot(procs['ING71_MEC_230309_001_Behav_Fr1-11947_proc']['pupil'][0]['area_smooth'])\n",
    "# plt.xlim((500,800))\n",
    "# plt.ylim((100,125))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More interesting data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = list(procs.values())[0]\n",
    "\n",
    "print(proc.keys())\n",
    "print(proc['pupil'][0].keys())\n",
    "\n",
    "print(np.shape(proc['pupil'][0]['axdir']))\n",
    "print(np.shape(proc['pupil'][0]['axlen']))\n",
    "# print(proc['pupil'][0]['axdir'])\n",
    "# print(proc['pupil'][0]['axlen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(proc['pupil'][0]['axlen'][:,0])\n",
    "plt.plot(proc['pupil'][0]['axlen'][:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like axlen and axdir refer to the axis that make up the tracker ellipse around the pupil. They seem to coincide very well with the area, which is expected as the area is calculated from the ellipse. We assume that axdir is the direction of the two axis making up the ellipse, and axlen the length of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc['rois'][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like rois contain little data of interest for further analysis. It could be interesting for understanding what we have done when creating the ROIs, so one could argue that the proc-files (per folder, as the ROI is the same for an entire folder. Could call it sample or something) should be saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Ly', 'Lx' \n",
    "print(proc['Lx'])\n",
    "print(proc['Ly'])\n",
    "print(86/3*66/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume the pupil makes up about 1/3 of the x-dir and y-dir. We see that the number of pixels within this fram seem to correspond with the y-axis of the area plots. \n",
    "\n",
    "When trying with two different files (within the same folder). Lx and Ly stay constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'avgframe':  list of average frames for each video from a subset of frames (binned by sbin) \n",
    "# 'avgmotion':  list of average motions for each video from a subset of frames (binned by sbin)\n",
    "print(np.shape(proc['avgframe']))\n",
    "print(proc['avgframe'])\n",
    "plt.plot(proc['avgframe'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(proc['avgmotion']))\n",
    "print(proc['avgmotion'])\n",
    "plt.plot(proc['avgmotion'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_proc, negative ,positive, reward, aversive = get_experiment_n_day_k('03', 230309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = len(positive)\n",
    "ds_proc = sp.signal.resample(c_proc, n_points) #ds stands for downsampled\n",
    "\n",
    "plt.plot(ds_proc)\n",
    "plt.plot(c_proc)\n",
    "plt.show()\n",
    "\n",
    "#Plot with downsampeled \n",
    "plt.plot(ds_proc)\n",
    "plt.scatter(np.arange(len(positive)), positive*ds_proc, 5, color='r')\n",
    "# plt.xlim(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using decimate\n",
    "\n",
    "ds_proc_d  = sp.signal.decimate(c_proc, 2)\n",
    " \n",
    "plt.plot(ds_proc_d)\n",
    "plt.plot(c_proc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking various ROIs for processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to check the difference of creating one sampl.npy-file per folder (general) and compare with the results from creating one per video (individual). Starting with folder /Volumes/T7/ING71_MEC_230309/AVI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading general:\n",
    "resultfolder_general = '/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy' \n",
    "procs_general = create_procs(resultfolder_general)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading individuals and comparing:\n",
    "\n",
    "proc_001_ind = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_001_Behav_Fr1-11947_proc.npy', allow_pickle=True).item()\n",
    "proc_001_gen = procs_general['ING71_MEC_230309_001_Behav_Fr1-11947_proc']\n",
    "\n",
    "plot_area(proc_001_gen, show=False)\n",
    "plot_area(proc_001_ind)\n",
    "\n",
    "\n",
    "proc_002_ind = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_002_Behav_Fr11949-23896_proc.npy', allow_pickle=True).item()\n",
    "proc_002_gen = procs_general['ING71_MEC_230309_002_Behav_Fr11949-23896_proc']\n",
    "\n",
    "plot_area(proc_002_gen, show=False)\n",
    "plot_area(proc_002_ind)\n",
    "\n",
    "\n",
    "proc_003_ind = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_003_Behav_Fr23897-35844_proc.npy', allow_pickle=True).item()\n",
    "proc_003_gen = procs_general['ING71_MEC_230309_003_Behav_Fr23897-35844_proc']\n",
    "\n",
    "plot_area(proc_003_gen, show=False)\n",
    "plot_area(proc_003_ind)\n",
    "\n",
    "\n",
    "proc_009_ind = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_009_Behav_Fr47793-59740_proc.npy', allow_pickle=True).item()\n",
    "proc_009_gen = procs_general['ING71_MEC_230309_009_Behav_Fr47793-59740_proc']\n",
    "\n",
    "plot_area(proc_009_gen, show=False)\n",
    "plot_area(proc_009_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the shape is kept rather constant although the absolute value seems to vary some. One can assume that some of this is due to the individual altering of saturation being better than the general one. Seems like the pupil is mostly within the defined region.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checkin the original one (should overlap completely):\n",
    "proc_000_ind = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_000_Behav_Fr1-9973_proc_wrong.npy', allow_pickle=True).item()\n",
    "proc_000_gen = procs_general['ING71_MEC_230309_000_Behav_Fr1-9973_proc']\n",
    "\n",
    "plot_area(proc_000_gen, show=False)\n",
    "plot_area(proc_000_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting! Not even the original one overlaps completely... Here the .npy-file was first processed in the GUI (yielding the green graph) and then that proc-file was used to process the entire folder (including the purple graph). Could it be that there is some randomness to the calculations which yield the difference in result? This was very interesting, indeed. Could it be that the saturation is not saved in the proc-file which is used for processing, but only employed when processing inside the GUI? This could be checked out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_000_gen['rois'][0]['saturation'])\n",
    "print(proc_000_ind['rois'][0]['saturation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very interesting... It seems the saturation is different in the two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_000_gen['rois'][0]['yrange'])\n",
    "print(proc_000_ind['rois'][0]['yrange'])\n",
    "\n",
    "print(proc_000_gen['rois'][0]['xrange'])\n",
    "print(proc_000_ind['rois'][0]['xrange'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_000_gen['rois'][0]['ellipse'])\n",
    "print(proc_000_ind['rois'][0]['ellipse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(proc_000_ind['rois'][0]['ellipse'], cmap='plasma')\n",
    "plt.imshow(proc_000_gen['rois'][0]['ellipse'], alpha=0.7, cmap='plasma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that there is not a complete overlap between the two. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare procs for '/Volumes/T7/ING71_MEC_230317'\n",
    "Would like to compare proc before and after processing (through facemap_tools)\n",
    "\n",
    "Now with folder '/Volumes/T7/ING71_MEC_230317' (would have liked to try with the other mouse, but this is the only data I have access to at the moment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_b4_proc = np.load('/Volumes/T7/ING71_MEC_230317/AVI/ING71_MEC_230317_000_Behav_Fr1-9973_unproc_proc.npy', allow_pickle=True).item()\n",
    "proc_af_proc = np.load('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy/ING71_MEC_230317_000_Behav_Fr1-9973_proc.npy', allow_pickle=True).item()\n",
    "\n",
    "print(proc_b4_proc['rois'])\n",
    "print(proc_af_proc['rois'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seem to be identical! \n",
    "\n",
    "Would now like to process it trough the gui and compare it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_af_gui_proc = np.load('/Volumes/T7/ING71_MEC_230317/AVI/ING71_MEC_230317_000_Behav_Fr1-9973_proc.npy', allow_pickle=True).item()\n",
    "\n",
    "print(proc_b4_proc['rois'])\n",
    "print(proc_af_gui_proc['rois'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What? This still seem identical..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_area(proc_af_proc, show=False)\n",
    "plot_area(proc_af_gui_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, so now it completely overlaps... What did I do before? Haha.\n",
    "\n",
    "Perhaps I sent in the  wrong npy-file while processing the folder? Perhaps I sent in the wrong path and it ended up using sample or something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at sample.npy to see if this is the one who's been used \n",
    "proc_sample = np.load('/Users/annapaulinehjertvikaasen/Documents/2. UiO/Sommerjobb - Frederik/Sommerjobb 2023/MouseProject/MouseProjectGH/ING71_MEC_230309/AVI/sample.npy', allow_pickle=True).item()\n",
    "print(proc_sample['rois'][0]['saturation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_sample_2 = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_sample.npy', allow_pickle=True).item()\n",
    "print(proc_sample_2['rois'][0]['saturation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! Here we see what's happened! I have perhaps forgotten to send in the a path to the proc-file. \n",
    "\n",
    "However, when looking at the terminal history, this is not what happened. Looks like it should have used the path I sent in, also when looking at the function. \n",
    "\n",
    "![](figures/terminal.png)\n",
    "\n",
    "To test this hypothesis though, we could process the ---_sample.npy file and compare. Should then see a complete overlap. If this is the case then the results above are valid. \n",
    "\n",
    "\n",
    "However, I cannot upload ---_sample.npy to the GUI since Eirik created that, hahah.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next folder: '/Volumes/T7/ING71_MEC_230317'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs_17_general = create_procs('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_17_001_ind = np.load('/Volumes/T7/ING71_MEC_230317/AVI/ING71_MEC_230317_001_Behav_Fr1-11947_proc.npy', allow_pickle=True).item()\n",
    "proc_17_001_gen = procs_17_general['ING71_MEC_230317_001_Behav_Fr1-11947_proc']\n",
    "\n",
    "plot_area(proc_17_001_gen, show=False)\n",
    "plot_area(proc_17_001_ind)\n",
    "\n",
    "\n",
    "proc_17_002_ind = np.load('/Volumes/T7/ING71_MEC_230317/AVI/ING71_MEC_230317_002_Behav_Fr11949-23896_proc.npy', allow_pickle=True).item()\n",
    "proc_17_002_gen = procs_17_general['ING71_MEC_230317_002_Behav_Fr11949-23896_proc']\n",
    "\n",
    "plot_area(proc_17_002_gen, show=False)\n",
    "plot_area(proc_17_002_ind)\n",
    "\n",
    "\n",
    "proc_17_003_ind = np.load('/Volumes/T7/ING71_MEC_230317/AVI/ING71_MEC_230317_003_Behav_Fr23897-35844_proc.npy', allow_pickle=True).item()\n",
    "proc_17_003_gen = procs_17_general['ING71_MEC_230317_003_Behav_Fr23897-35844_proc']\n",
    "\n",
    "plot_area(proc_17_003_gen, show=False)\n",
    "plot_area(proc_17_003_ind, alpha=0.65)\n",
    "\n",
    "\n",
    "proc_17_009_ind = np.load('/Volumes/T7/ING71_MEC_230317/AVI/ING71_MEC_230317_009_Behav_Fr47793-59738_proc.npy', allow_pickle=True).item()\n",
    "proc_17_009_gen = procs_17_general['ING71_MEC_230317_009_Behav_Fr47793-59738_proc']\n",
    "\n",
    "plot_area(proc_17_009_gen, show=False)\n",
    "plot_area(proc_17_009_ind, alpha=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again it looks like the general shape of the area stays constant. In most cases there seems to be a shift, perhaps due to the saturation settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare area and area smooth (Runwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas, areas_smooth = create_areas('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(areas['000'])\n",
    "plt.plot(areas_smooth['000'], alpha=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like 'area smooth' differs from 'area' quite alot, even though the general shape of the signal is the same. However, I find it very strange that 'amooth' has some \"blinking\" that area does not have..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(areas['001'])\n",
    "plt.plot(areas_smooth['001'], alpha=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the 'area smooth' overlaps rather well with the 'area' in this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(areas['002'])\n",
    "plt.plot(areas_smooth['002'], alpha=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(areas['003'])\n",
    "plt.plot(areas_smooth['003'], alpha=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(areas['009'])\n",
    "plt.plot(areas_smooth['009'], alpha=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in 000 and 009 the 'area smooth' seems to create downwards spikes. Now, zooming in (the 4th 009 video, ING71_MEC_230317_009_Behav_Fr35845-47792):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(areas['009'])\n",
    "plt.plot(areas_smooth['009'], alpha=0.65)\n",
    "plt.xlim((36000,48000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the GUI, these spikes seem to be gone. Also, when inspecting the video where the spikes should be, I found nothing of interest. However, the mouse blinked around 5500 (In pur plot that shoud be 41 500), and this was not marked with a spike. It also blinked around 6800 (42 800). Both of these blinks were marked by the SVD. It should also be mentioned that the pupil in this case was a little bit cut off at the bottom.\n",
    "\n",
    "It seems more and more like the software lacks in the classifications of blinking (at least when looking at the area). However, this is not our field of interest and might be ignored. \n",
    "\n",
    "In the comparison of area and area smooth we have yet to see an advantage of either as opposed to the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavioral data\n",
    "\n",
    "Here we use the downsampling currently yielding the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_and_plot(c_proc, cue):\n",
    "    \"\"\"Downsample and plot \n",
    "\n",
    "    Args:\n",
    "        c_proc (_type_): _description_\n",
    "        cue (_type_): _description_\n",
    "    \"\"\"\n",
    "    n_points = len(cue)\n",
    "    ds_proc = sp.signal.resample(c_proc, n_points)\n",
    "    plt.plot(ds_proc)\n",
    "    plt.scatter(np.arange(n_points), cue*np.max(ds_proc), 6, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_proc_1, negative_1 ,positive_1, reward_1, aversive_1 = get_experiment_n_day_k('01', 230317)\n",
    "c_proc_2, negative_2 ,positive_2, reward_2, aversive_2 = get_experiment_n_day_k('02', 230317)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = len(positive_1)\n",
    "\n",
    "c_proc_1 = remove_outliers(c_proc_1)\n",
    "\n",
    "ds_proc = sp.signal.resample(c_proc_1, n_points)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(ds_proc)\n",
    "plt.scatter(np.arange(n_points), positive_1*np.max(ds_proc), 20)\n",
    "plt.scatter(np.arange(n_points), reward_1*np.max(ds_proc), 20)\n",
    "plt.scatter(np.arange(n_points), negative_1*np.max(ds_proc), 20)\n",
    "plt.scatter(np.arange(n_points), aversive_1*np.max(ds_proc), 20)\n",
    "\n",
    "# plt.xlim((0,4000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could be interesting to look at more than one folder. Maybe we should have a plotting bonanza! In that case we can use Eirik's results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwrite Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overwrite_filenames(result_folder, avi_folder=None):\n",
    "    \"\"\"\n",
    "    Takes in a resultfolder (full of npy-files) and overwrites the 'filenames' and 'save_path' so that the procs contain the correct file-path and can be evaluated in the gui. \n",
    "\n",
    "    eg. results_folder: '/Volumes/T7/ING71_MEC_230310/AVI/resultsnpy' \n",
    "    results_folder is the same as save_path\n",
    "\n",
    "    filenames requires the avi file corresponding to the npy-file.\n",
    "    \"\"\"\n",
    "\n",
    "    #set avi_folder to the folder \"above\" result_folder:\n",
    "    # Simply removing the /resultsnpy (seems too specific, but) \n",
    "    # if avi_folder == None:\n",
    "    #     avi_folder = result_folder[:-11]\n",
    "    if avi_folder == None:\n",
    "        avi_folder = result_folder[:32]\n",
    "    ### NB! Now it only works with mac! \n",
    "\n",
    "\n",
    "    files = os.listdir(result_folder)\n",
    "    clean_files = []\n",
    "\n",
    "    #Checks for .avi files and catches exception if filenames are shorter than 4 letters.\n",
    "    for file in files:\n",
    "        try:\n",
    "            if file[-4:] == \".npy\":\n",
    "                clean_files.append(file)\n",
    "        except:\n",
    "            print('Invalid file name')\n",
    "\n",
    "    for filename in clean_files:\n",
    "        npy_path = os.path.join(result_folder, filename)\n",
    "        proc = np.load(npy_path, allow_pickle=True).item() \n",
    "\n",
    "        avi_filename = filename[:-9] + '.avi'\n",
    "        avi_path = os.path.join(avi_folder, avi_filename)\n",
    "\n",
    "        #Overwrite:\n",
    "        proc['filenames'] = [[avi_path]]\n",
    "        proc['save_path'] = result_folder\n",
    "\n",
    "        np.save(npy_path, proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite_filenames('/Volumes/T7/ING71_MEC_230310/AVI/resultsnpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the two procs \n",
    "\n",
    "proc_09 = np.load('/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy/ING71_MEC_230309_000_Behav_Fr1-9973_proc.npy', allow_pickle=True).item()\n",
    "proc_10 = np.load('/Volumes/T7/ING71_MEC_230310/AVI/resultsnpy/ING71_MEC_230310_000_Behav_Fr1-9973_proc.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_09['filenames'])\n",
    "print(proc_10['filenames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_09['save_path'])\n",
    "print(proc_10['save_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite_filenames('/Volumes/T7/ING71_MEC_230313/AVI/resultsnpy_E_mac')\n",
    "# overwrite_filenames('/Volumes/T7/ING71_MEC_230314/AVI/resultsnpy_E_mac')\n",
    "# overwrite_filenames('/Volumes/T7/ING71_MEC_230315/AVI/resultsnpy_E_mac')\n",
    "# overwrite_filenames('/Volumes/T7/ING71_MEC_230316/AVI/resultsnpy_E_mac')\n",
    "overwrite_filenames('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy_E_mac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For sample file\n",
    "It would be cool to be able to test the sample-file on several avi-files before processing. However, that would mean preprocessing it before every load :/ Minght not be smooth enough, and we could maybe just process it and then check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_sample = np.load('/Volumes/T7/ING71_MEC_230309/AVI/ING71_MEC_230309_sample.npy', allow_pickle=True).item()\n",
    "print(proc_sample['filenames'], proc_sample['save_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Bonanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def plot_areas(run_based_folder):\n",
    "    areas, areas_smooth = create_areas(run_based_folder)\n",
    "    nrows = len(areas.keys())\n",
    "\n",
    "    areas_sorted = OrderedDict(sorted(areas.items()))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,20), nrows=nrows, ncols=1)\n",
    "    for i in range(nrows):\n",
    "        key = list(areas_sorted.keys())[i]\n",
    "        # ax[i].plot(areas[key])\n",
    "        ax[i].plot(areas_smooth[key], alpha=0.65)\n",
    "        ax[i].set_title(run_based_folder + '  Run: ' + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areas('/Volumes/T7/ING71_MEC_230310/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areas('/Volumes/T7/ING71_MEC_230314/AVI/resultsnpy_E/run_based')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areas('/Volumes/T7/ING71_MEC_230315/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areas('/Volumes/T7/ING71_MEC_230316/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areas('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areas('/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy/run_based')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes for a more general plotting:\n",
    "take the keys into direct consideration as they seem to vary quite a lot (done)\n",
    "\n",
    "\n",
    "What's annoying about these results is that I can go into the gui and look into them... I mean some of them seem weird. (This is fixed now! Just use the 'overwrite_filenam'-function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting runs on top of eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_runs(run_based_folder):\n",
    "    areas, areas_smooth = create_areas(run_based_folder)\n",
    "    nkeys = len(areas.keys())\n",
    "\n",
    "    areas_sorted = OrderedDict(sorted(areas.items()))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    for i in range(nkeys):\n",
    "        key = list(areas_sorted.keys())[i]\n",
    "        # ax.plot(areas[key], label=key)\n",
    "        ax.plot(areas_smooth[key], label=key)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230310/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230313/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230314/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230315/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230316/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy_E/run_based')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now with scaling \n",
    "\n",
    "Want to compare eg training runs (001/002/003) with baseline run (000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "def plot_runs(run_based_folder, keys_idx=None, rmv_out=False):\n",
    "    areas, areas_smooth = create_areas(run_based_folder)\n",
    "\n",
    "    nkeys = len(areas.keys())\n",
    "    if keys_idx==None:\n",
    "        keys_idx = list(range(nkeys))\n",
    "\n",
    "    areas_sorted = OrderedDict(sorted(areas.items()))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    for i in keys_idx:\n",
    "        key = list(areas_sorted.keys())[i]\n",
    "\n",
    "        area_smooth = areas_smooth[key]\n",
    "        if rmv_out:\n",
    "            area_smooth = remove_outliers(area_smooth)\n",
    "        # ax.plot(areas[key], label=key)\n",
    "        ax.plot(minmax_scale(area_smooth), label=key)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_runs('/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy_E/run_based', [0,1], rmv_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_runs('/Volumes/T7/ING71_MEC_230309/AVI/resultsnpy_E/run_based', [0, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would say 009 and 000 look quite similar in this case. Seems like the training runs have a more caotic pattern with less large oscillations. The resting run has some very large oscillations. However, I feel like the large oscillations in the BL and resting run might be easier to see as they have some large deviations squishing the rest of the graph together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing with a new ROI\n",
    "\n",
    "In this section we will compare the results run on Eirik's computer (possibly run with one ROI for all folders) and Anna's (one ROI per folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(avi_folder):\n",
    "    \"\"\"\n",
    "    Assuming the avi_folder contains two result folders. \n",
    "    \"\"\"\n",
    "    RB_path = os.path.join(avi_folder, 'resultsnpy/run_based')          #Path to runbased folder\n",
    "    RB_path_E = os.path.join(avi_folder, 'resultsnpy_E/run_based')\n",
    "\n",
    "    areas = create_areas(RB_path)[0]\n",
    "    areas_E = create_areas(RB_path_E)[0]\n",
    "\n",
    "    nrows = len(areas.keys())\n",
    "\n",
    "    areas_sorted = OrderedDict(sorted(areas.items()))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,20), nrows=nrows, ncols=1)\n",
    "    for i in range(nrows):\n",
    "        key = list(areas_sorted.keys())[i]\n",
    "        ax[i].plot(areas[key])\n",
    "        ax[i].plot(areas_E[key], alpha=0.65)\n",
    "        ax[i].set_title(avi_folder + '  Run: ' + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_results('/Volumes/T7/ING71_MEC_230310/AVI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have looked into the case of 010 (last plot); seems to be related to a lot of blinking in combination with something that looks like grooming. \n",
    "\n",
    "The increase in 001 could perhaps be the adjustment to a brighter light."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_results('/Volumes/T7/ING71_MEC_230309/AVI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Someting interesting! It looks like the values go below 0. And, NB, this is befor downsampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_results('/Volumes/T7/ING71_MEC_230317/AVI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas, areas_smooth = create_areas('/Volumes/T7/ING71_MEC_230317/AVI/resultsnpy/run_based')\n",
    "\n",
    "\n",
    "print(type(areas['000']))\n",
    "area_0 = areas['000']\n",
    "area_0  =remove_outliers(area_0)\n",
    "area_0_fft = sp.fft.ifft(area_0)\n",
    "\n",
    "x = np.arange(len(area_0))\n",
    "x_fft = sp.fft.fft(x)\n",
    "\n",
    "\n",
    "# plt.plot(x_fft, area_0_fft)\n",
    "# plt.xlim((-0.2*10**5,0.2*10**5))\n",
    "# plt.xlim((-14000, -13500))\n",
    "# plt.ylim((-20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
